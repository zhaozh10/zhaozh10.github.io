<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <meta
      name="google-site-verification"
      content="eoPCGBBxDIK0Ff9Dk_dXsuHMTNzzSEZMbsfO4zriBK8"
    />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <link rel="shortcut icon" href="./images/ps.ico" />
    <meta
      name="keywords"
      content="赵子皓, Zihao Zhao, ShanghaiTech, IDEA Lab, Dinggang Shen, 上海科技大学, 沈定刚"
    />
    <meta name="description" content="Zihao Zhao&#39;s Home Page" />
    <!--    <link href="main.css" media="all" rel="stylesheet">-->
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <title>Zihao Zhao | 赵子皓</title>
  </head>

  <body>
    <table>
      <tbody>
        <tr>
          <!-- <td>
				<img src="./images/zihao.jpg" border="0" width="200"><br>
			</td>
			<td>&nbsp</td> -->
          <td width="670">
            <div id="toptitle">
              <h1 style="color: #c82423">Zihao Zhao</h1>
              <h1></h1>
            </div>
            <!-- http://idea.bme.shanghaitech.edu.cn/ -->
            <h3>Master Student</h3>
            <p>
              393 Middle Huaxia Road, Shanghai<br />
              <a href="https://bme.shanghaitech.edu.cn/" target="_blank"
                >School of Biomedical Engineering</a
              >
              <a
                href="http://idea.bme.shanghaitech.edu.cn/home/"
                target="_blank"
                >[IDEA Lab]</a
              >
              <br />
              <a href="https://www.shanghaitech.edu.cn/eng/" target="_blank"
                >ShanghaiTech University</a
              >
              <br /><br />
              Email: zihaozhao10@gmail.com <br />
            </p>
            <p>
              <a
                href="https://scholar.google.com/citations?user=Novd9cUAAAAJ&hl=en"
                target="_blank"
                ><img
                  src="./images/google_scholar3.png"
                  height="30px"
                  style="margin-bottom: -3px"
              /></a>
              <a href="https://github.com/zhaozh10" target="_blank"
                ><img
                  src="./images/github_s.jpg"
                  height="30px"
                  style="margin-bottom: -3px"
              /></a>
              <a href="./zihaozhao_cv.pdf" target="_blank"
                ><img
                  src="./images/cv2.png"
                  height="30px"
                  style="margin-bottom: -3px"
              /></a>
            </p>
          </td>
          <td><img src="./images/zihao.jpg" border="0" width="200" /><br /></td>
        </tr>
        <tr></tr>
      </tbody>
    </table>

    <h2>
      <a id="C1"><font color="#CB4335">About Me</font></a>
    </h2>
    <p>
      I am currently a Master's student at the School of Biomedical Engineering at ShanghaiTech University, supervised by Prof. Dinggang Shen.
    </p>
    <p>
	My research primarily focuses on eye-tracking enhanced medical image analysis, as well as exploring the integration of large language models (LLMs) into computer-aided diagnosis (CAD)
    <!-- During my Master's program, I have dedicated my efforts to aligning CAD models and human perception.  -->
	, which encompasses two critical aspects:
	<ul>
              <li>Vision level alignment: Utilizing eye-tracking data, we seeks to align the visual processing capabilities of CAD systems with those of human experts.
</li>
              <li>Language level alignment: We employ the reasoning capabilities of LLMs to convert difficult-to-interpret results from CAD models into comprehensive and explainable reports. 
                <!-- This not only aids in making diagnoses more accessible but also enhances the communicative efficiency between medical professionals and AI systems. -->
</li>
    </ul>
<!-- In the initial stages of my Master's thesis, I investigated Vision-Level and Language-Level Alignment seperately. Currently, in the culminating phase, I am working to integrate these alignments to develop a more cohesive and intuitive diagnostic system that align with human perception. -->
    </p>

    <h2>
      <a id="C2"><font color="#CB4335">News</font></a>
    </h2>
    <ul>
      <div
        style="
          height: 9em;
          /* width: fit-content; */
		  width: 80%;
          overflow: auto;
          background: #ffffff;
        "
      >
      <li>
          <p>[Feb/14/2025] One paper accepted by IPMI 2025.</p>
        </li>
      <li>
          <p>[Jan/07/2025] Two papers (co-first author) accepted by IEEE TMI and Pattern Recognition.</p>
        </li>
      <li>
          <p>[Aug/20/2024] ChatCAD was finally been accepted by COMMSENG!</p>
        </li>
      <li>
          <p>[Jun/19/2024] Two papers accepted by MICCAI 2024.</p>
        </li>
	<li>
          <p>[May/05/2024] One paper accepted by IEEE TMI.</p>
        </li>
        <li>
          <p>[Feb/03/2024] One paper accepted by ISBI 2024.</p>
        </li>
        <li>
          <p>[Dec/09/2023] One paper accepted by AAAI 2024.</p>
        </li>
        <li>
          <p>[Dec/05/2023] My Google Scholar profile reached 100 citations!</p>
        </li>
        <li>
          <p>
            [Jul/25/2022] I officially join Prof. Dinggang Shen's research lab.
          </p>
        </li>
      </div>
    </ul>
    <!-- <h2>
      <a id="edu"><font color="#CB4335">Education</font></a>
    </h2> -->
    

    <h2>
      <a id="C3"><font color="#CB4335">Research</font></a>
    </h2>

    <table id="tbPublications" width="100%">
      <tr>
        <td width="346" , style="text-align: center">
          <img
            src="images/CLIP_Survey.png"
            width="305px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong>CLIP in medical imaging: A survey</strong><br />
          <b>Zihao Zhao</b>, Yuxiao Liu, Han Wu, Mei Wang, Yonghao Li, Sheng Wang, Lin
          Teng, Disheng Liu, Zhiming Cui, Qian Wang, Dinggang Shen<br />
          <em>Medical Image Analysis (<b>MedIA</b>)</em>, 2025.
          <p>
            [<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841525000982" target="_blank">paper</a
            >] [<a
              href="https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging"
              target="_blank"
              >code</a
            >]
            <a
              href="https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/zhaozh10/Awesome-CLIP-in-Medical-Imaging?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        <td width="346" , style="text-align: center; vertical-align: top">
          <img
            src="images/McGIP.png"
            width="305px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong
            >Mining Gaze for Contrastive Learning toward Computer-assisted
            Diagnosis</strong
          ><br />
          <b><b>Zihao Zhao</b></b
          >, Sheng Wang, Qian Wang, Dinggang Shen<br />
          <em
            >Proceedings of the AAAI Conference on Artificial Intelligence
            (<b>AAAI</b>)</em
          >, 2024.
          <p>
            [<a
              href="https://ojs.aaai.org/index.php/AAAI/article/view/28586"
              target="_blank"
              >paper</a
            >] 
			[<a
              href="./images/AAAI-McGIP-Poster.pdf"
              target="_blank"
              >poster</a
            >]
			[<a href="https://github.com/zhaozh10/McGIP" target="_blank"
              >code</a
            >]
            <a
              href="https://github.com/zhaozh10/McGIP"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/zhaozh10/McGIP?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        <td width="346" , style="text-align: center; vertical-align: top">
          <img
            src="images/ChatCAD+.png"
            width="275px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong
            >ChatCAD+: Towards a Universal and Reliable Interactive CAD using
            LLMs</strong
          ><br />
          <b>Zihao Zhao</b>, Sheng Wang, Jinchen Gu, Yitao Zhu, Lanzhuju
          Mei, Zixu Zhuang, Zhiming Cui, Qian Wang, Dinggang Shen<br />
          <em>IEEE Transactions on Medical Imaging (<b>TMI</b>)</em>, 2024.
          <p>
            [<a href="https://ieeexplore.ieee.org/abstract/document/10522762" target="_blank">paper</a
            >] [<a href="https://github.com/zhaozh10/ChatCAD" target="_blank"
              >code</a
            >]
            <a
              href="https://github.com/zhaozh10/ChatCAD"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/zhaozh10/ChatCAD?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        <td width="346" , style="text-align: center; vertical-align: top">
          <img
            src="images/ChatCAD.png"
            width="305px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong
            >Interactive Computer-Aided Diagnosis on Medical Image
            using Large Language Models <span style="color: #8b0000">(Editor's Choice 2024)</span> </strong
          ><br />
          Sheng Wang<span>&#42;</span>, <b>Zihao Zhao<span>&#42;</span></b>, Xi Ouyang, Qian Wang, Dinggang Shen<br />
          <em>Communications Engineering</em>, 2024.
          <p>
            [<a href="https://www.nature.com/articles/s44172-024-00271-8" target="_blank">paper</a
            >] [<a href="https://github.com/zhaozh10/ChatCAD" target="_blank"
              >code</a
            >] [<a href="https://www.nature.com/articles/s44172-024-00335-9" target="_blank"
              >editor's choice</a
            >]
            <a
              href="https://github.com/zhaozh10/ChatCAD"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/zhaozh10/ChatCAD?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        <td width="346" , style="text-align: center; vertical-align: top">
          <img
            src="images/FocusContrast.png"
            width="305px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong
            >Crafting Good Views of Medical Images for Contrastive Learning via
            Expert-level Visual Attention
            <span style="color: #8b0000">(Oral)</span></strong
          ><br />
          Sheng Wang, <b>Zihao Zhao</b>, Lichi Zhang, Dinggang Shen, Qian
          Wang<br />
          <em>NeurIPS Workshop Gaze Meets ML</em>, 2023.
          <p>
            [<a href="https://openreview.net/pdf?id=JBIfteTlxk" target="_blank"
              >paper</a
            >] [<a
              href="https://github.com/JamesQFreeman/MicEye"
              target="_blank"
              >code</a
            >]
            <a
              href="https://github.com/JamesQFreeman/MicEye"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/JamesQFreeman/MicEye?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        <td width="346" , style="text-align: center; vertical-align: top">
          <img
            src="images/melo.png"
            width="305px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong
            >MeLo: Low-rank Adaptation is Better than Fine-tuning for Medical
            Image Diagnosis <span style="color: #8b0000">(Oral)</span></strong
          ><br />
          Yitao Zhu, Zhenrong Shen, <b>Zihao Zhao</b>, Sheng Wang, Xin Wang,
          Xiangyu Zhao, Dinggang Shen, Qian Wang<br />
          <em
            >IEEE International Symposium on Biomedical Imaging
            (<b>ISBI</b>)</em
          >, 2024.
          <p>
            [<a href="https://arxiv.org/abs/2311.08236" target="_blank">paper</a
            >] [<a
              href="https://github.com/JamesQFreeman/LoRA-ViT"
              target="_blank"
              >code</a
            >]
            <a
              href="https://github.com/JamesQFreeman/LoRA-ViT"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/JamesQFreeman/LoRA-ViT?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        <td width="346" , style="text-align: center; vertical-align: top">
          <img
            src="images/doctorglm_pipeline.png"
            width="305px"
            style="box-shadow: 4px 4px 8px #888"
          />
        </td>
        <td>
          <strong
            >DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean
            Task</strong
          ><br />
          Honglin Xiong, Sheng Wang, Yitao Zhu, <b>Zihao Zhao</b>, Yuxiao
          Liu, Linlin Huang, Qian Wang, Dinggang Shen<br />
          <em>ArXiv</em>, 2023.
          <p>
            [<a href="https://xionghonglin.github.io/DoctorGLM/" target="_blank"
              >project page</a
            >] [<a href="https://arxiv.org/abs/2304.01097" target="_blank"
              >paper</a
            >] [<a
              href="https://github.com/xionghonglin/DoctorGLM"
              target="_blank"
              >code</a
            >]
            <a
              href="https://github.com/xionghonglin/DoctorGLM"
              style="vertical-align: top"
              ><img
                src="https://img.shields.io/github/stars/xionghonglin/DoctorGLM?style=social"
                alt="GitHub stars"
            /></a>
          </p>
        </td>
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
      <tr>
        &nbsp
      </tr>
    </table>

    <h2><font color="#CB4335">Soical Activity</font></h2>
    <b>Reviewer</b> for:<br />
    IEEE Transactions on Medical Imaging<br />
    IEEE Journal of Biomedical and Health Informatics<br />
    Pattern Recognition<br />
    Neural Networks<br />
    <b>Teaching Assistant</b> for:<br />
    BME2106 Medical Big Data and Artificial Intelligence - Spring 2024<br />
    <br />
    <h2><font color="#CB4335">Miscellaneous</font></h2>
    <ul>
      <li>I am a loyal fan of Hajime Isayama's ATTACK ON TITAN.</li>
      <li>
        PlayStation Platinum Trophy: <a href="https://godofwar.fandom.com/wiki/God_of_War_III"> God of War III</a>, <a href="https://godofwar.fandom.com/wiki/God_of_War_(2018)">God of War (2018)</a>, <a href="https://godofwar.fandom.com/wiki/God_of_War_Ragnar%C3%B6k">God of War:
        Ragnarök</a>, <a href="https://en.wikipedia.org/wiki/Nioh">Nioh</a>, <a href="https://nioh2.wiki.fextralife.com/Nioh+2+Wiki">Nioh 2</a>, <a href="https://riseoftheronin.wiki.fextralife.com/Rise+of+the+Ronin+Wiki"> Rise of the Rōnin</a>, <a href="https://teamninja-studio.com/wolong/">Wo Long: Fallen Dynasty</a>, <a href="https://insomniac.games/game/marvels-spider-man-2/"> Marvel's Spider-Man 2</a>.
      </li>
    </ul>
    <div id="visitor-counter" style="text-align: left; margin: 0px;">
        <h2><font color="#CB4335">Visitors</font></h2>
        <div style="display:inline-block;width:300px;">
            <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=CaZchN91gfT1nq2mxAMf5a9QRRABuRaXOBEzgFgnK9k&cl=ffffff&w=a"></script>
        </div>
    </div>
  </body>
</html>
